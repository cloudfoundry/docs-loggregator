---
title: Loggregator Guide for Cloud Foundry Operators
owner: Logging and Metrics
---

<strong><%= modified_date %></strong>

This topic contains information for Cloud Foundry deployments operators about how to configure the [Loggregator system](./architecture.html) to avoid data loss with high volumes of logging and metrics data.

## <a id='throughput-reliability'></a> Loggregator Message Throughput and Reliability

For determining the message throughput and reliability rates of your Loggregator system, see the section below.

### <a id='throughput-rate'></a> Measuring Message Throughput

To measure the message throughput of the Loggregator system, you can monitor the total number of egress messages from all Metrons on your platform using the `metron.egress` metric.

If you do not use a monitoring platform, you can follow the instructions below to measure the overall message throughput of your Loggregator system:

1. Log in to the Cloud Foundry Command Line Interface (cf CLI) with your admin credentials:
	<pre class='terminal'>$ cf login</pre>
1. [Install](cli-plugin.html#add) the Cloud Foundry Firehose plugin.
1. Install Pipe Viewer:
	<pre class='terminal'>$ apt-get install pv</pre>
1. Run the following command:
	<pre class='terminal'>$ cf nozzle -n | pv -l -i 10 -r > /dev/null</pre>

### <a id='reliability-rate'></a> Measuring Message Reliability

To measure the message reliability rate of your Loggregator system, you can run black-box tests. If you want to use this method, see the open-source [cf-logmon](https://github.com/cloudfoundry-incubator/cf-logmon) app and the configuration instructions provided in the README.md file.

## <a id='scaling'></a> Scaling Loggregator ##

Most Loggregator configurations are set to use preferred resource defaults. If you want to customize these defaults or plan the capacity of your Loggregator system, see the formulas below.

### Doppler

Doppler resources can require scaling to accommodate your overall log volume and envelope size. <%= vars.product_full %> recommends the following formula for determining the number of Doppler instances you need to achieve a loss rate of &lt; 1%:

<p class="tip"><em>Number of Doppler instances = Number of logs per second / 2,000</em></p>

You can also monitor and scale Doppler based on its ingress traffic. To do this, you need to sum two metrics and rate them per second:

<p class="tip"><em>Number of Doppler instances = <code>doppler.ingress</code> + <code>DopplerServer.listeners.receivedEnvelopes</code> / 10,000</em></p>

For ingress-based capacity planning, <%= vars.product_full %> recommends using maximum values over a two-week period and following the guidelines above for scaling Doppler.

### Traffic Controller

Traffic Controller resources are usually scaled in line with Doppler resources. <%= vars.product_full %> recommends the following formula for determining the number of Traffic Controller instances:

<p class="tip"><em>Number of Traffic Controller instances = Number of Doppler instances / 4</em></p>

In addition, Traffic Controller resources can require scaling to accommodate the number of your log streams and Firehose subscriptions.

<% if vars.product_name == 'CF' %>
<% else %>
<%= partial 'scaling_syslog_adapters' %>
<% end %>

See <%=vars.logg_scaling %> for more information about scaling the Loggregator system.

## <a id='scaling-nozzles'></a> Scaling Nozzles

You can scale a [nozzle](./architecture.html#nozzles) using the subscription ID specified when the nozzle connects to the Firehose. If you use the same subscription ID on each nozzle instance, the Firehose evenly distributes data across all instances of the nozzle.

For example, if you have two nozzle instances with the same subscription ID, the Firehose sends half of the data to one nozzle instance and half to the other. Similarly, if you have three nozzle instances with the same subscription ID, the Firehose sends one-third of the data to each instance.

If you want to scale a nozzle, the number of nozzle instances should match the number of Traffic Controller instances:

<p class="tip"><em>Number of nozzle instances = Number of Traffic Controller instances</em></p>

Stateless nozzles should handle scaling gracefully. If a nozzle buffers or caches the data, the nozzle author must test the results of scaling the number of nozzle instances up or down.

## <a id='slow-noz'></a> Slow Nozzle Alerts ##

The [Traffic Controller](./architecture.html#traffic-controller) alerts nozzles if they consume events too slowly.
If a nozzle falls behind, Loggregator alerts the nozzle in two ways:

- **TruncatingBuffer** alerts: If the nozzle consumes messages more slowly than they are produced, the Loggregator system may drop messages. In this case, Loggregator sends the log message, `TB: Output channel too full. Dropped N messages`, where `N` is the number of dropped messages. Loggregator also emits a **CounterEvent** with the name `doppler_proxy.slow_consumer`. The nozzle receives both messages from the Firehose, alerting the operator to the performance issue.

## <a id='syslog-forward'></a> Forwarding Logs to an External Service ##

You can configure <%= vars.product_full %> to forward log data from apps to an external aggregator service. [Using Log Management Services](../devguide/services/log-management.html) explains how to bind apps to the external service and configure it to receive logs from <%= vars.product_full %>.

## <a id='log-message-size'></a> Log Message Size Constraints

The Diego cell emits application logs as UDP messages to the Metron.
Diego breaks up log messages greater than approximately 60KiB into multiple envelopes to mitigate this constraint.
